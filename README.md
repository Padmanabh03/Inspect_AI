# InspectAI - Industrial Visual Inspection System

A production-ready anomaly detection system for industrial quality assurance. Built with PatchCore for unsupervised defect detection, featuring a complete web application with REST API and inspection console.

**ğŸ¯ What Makes This Special:**
- **Unsupervised Learning**: Trains on normal images onlyâ€”no need for labeled defects
- **Explainable Results**: Provides pixel-level heatmaps showing exactly where defects are located
- **Production-Ready**: Full web application with REST API, not just model scripts
- **Real-World Design**: Built for QA engineers, not ML researchers
- **Transparent Decisions**: Explicit thresholding logic, not black-box predictions

## ğŸ“Š Performance

**Achieved Results (MVTec Bottle Category):**
- **Image-Level AUROC**: 99.92% â­
- **Pixel-Level AUROC**: 95.52% âœ¨
- **100% Recall**: Catches all defects without missing any
- **Inference Speed**: ~4.5 images/second

## ğŸ¯ Features

- **Complete Web Application**: Full-stack solution with FastAPI backend and modern frontend
- **PatchCore Algorithm**: State-of-the-art anomaly detection using WideResNet50 backbone
- **Real-time Visualization**: Interactive heatmaps showing exact defect locations
- **Memory Bank**: Efficient coreset sampling to reduce memory footprint
- **Multi-Scale Features**: Extracts features from multiple layers (layer2 + layer3)
- **Automatic Thresholding**: Computes threshold from normal training data
- **REST API**: Complete API with model caching for production use
- **15 Product Categories**: Pre-trained models for bottle, cable, capsule, carpet, grid, hazelnut, leather, metal_nut, pill, screw, tile, toothbrush, transistor, wood, zipper
- **Comprehensive Evaluation**: Image-level and pixel-level AUROC metrics

## ğŸŒ Web Application

InspectAI includes a production-ready web inspection console:

### Interface Overview
![InspectAI Interface](images/4.png)
*Clean, intuitive interface for quality inspection with category selection and drag-and-drop upload*

**Features:**
- ğŸ¨ Modern UI with purple gradient design
- ğŸ“¤ Drag-and-drop image upload
- ğŸ“Š Real-time anomaly detection
- ğŸ”¥ Interactive heatmap visualization
- âœ… Clear PASS/FAIL decisions
- ğŸ“ˆ Detailed anomaly scores and thresholds

### Running the Application

**Start the server:**
```bash
python start_app.py
```

**Access:**
- **Web Interface**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

**Note**: This system runs on localhost. The model files (1.7GB total) exceed free hosting tier limits. Local deployment provides full functionality with excellent performance.

## ğŸ¯ Detection Examples

### âŒ Defect Detection (FAIL)

**Capsule with Crack** - Anomaly Score: 50.42
![Capsule Defect](images/5.png)
- âŒ **Decision**: FAIL
- ğŸ”´ Red heatmap highlights crack location
- ğŸ“Š Score: 50.42 (Threshold: 22.69)
- ğŸ¯ Precise defect localization in overlay

**Transistor Damage** - Anomaly Score: 40.38
![Transistor Defect](images/3.png)
- âŒ **Decision**: FAIL
- ğŸ”´ Burned/damaged chip component detected
- ğŸ“Š Score: 40.38 (Threshold: 29.63)
- ğŸ¯ Heatmap focuses on central defect

**Toothbrush Contamination** - Anomaly Score: 58.81
![Toothbrush Defect](images/2.png)
- âŒ **Decision**: FAIL
- ğŸ”´ Color/pattern anomalies detected
- ğŸ“Š Score: 58.81 (Threshold: 36.87)
- ğŸ¯ Multiple defect regions highlighted

### âœ… Normal Product (PASS)

**Good Bottle** - Anomaly Score: 15.78
![Normal Bottle](images/1.png)
- âœ… **Decision**: PASS
- ğŸ”µ Blue heatmap indicates normal regions
- ğŸ“Š Score: 15.78 < Threshold: 15.99
- âœ¨ Product passes quality inspection

## ğŸ“ Project Structure

```
Inspect_AI/
â”œâ”€â”€ patchcore/               # Core PatchCore module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py            # Main PatchCore model
â”‚   â”œâ”€â”€ feature_extractor.py # Feature extraction with WideResNet50
â”‚   â”œâ”€â”€ memory_bank.py      # Memory bank with coreset sampling
â”‚   â””â”€â”€ utils.py            # Utility functions
â”œâ”€â”€ train.py                # Training script
â”œâ”€â”€ inference.py            # Inference script
â”œâ”€â”€ evaluate.py             # Evaluation script
â”œâ”€â”€ config.py               # Configuration settings
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ mvtec_anomaly_detection/ # Dataset (already present)
â”œâ”€â”€ models/                 # Trained models (created during training)
â”‚   â””â”€â”€ patchcore/
â”‚       â””â”€â”€ bottle/
â”‚           â”œâ”€â”€ memory_bank.npy
â”‚           â””â”€â”€ config.json
â””â”€â”€ results/                # Inference results (created during inference)
    â””â”€â”€ bottle/
        â”œâ”€â”€ good/
        â”œâ”€â”€ broken_large/
        â””â”€â”€ evaluation/
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

**Note**: If you have a CUDA-capable GPU, the system will automatically use it. Otherwise, it will fall back to CPU (slower).

### 2. Train on Bottle Category (Single Category)

```bash
python train.py --category bottle
```

This will:
- Load all training images from `mvtec_anomaly_detection/bottle/train/good/`
- Extract features using WideResNet50
- Build memory bank with coreset sampling
- Compute anomaly threshold
- Save model to `models/patchcore/bottle/`

### 3. Run Inference

**Inference on all test images:**
```bash
python inference.py --category bottle
```

**Inference on a single image:**
```bash
python inference.py --category bottle --image "mvtec_anomaly_detection/bottle/test/broken_large/000.png"
```

### 4. Evaluate Performance

```bash
python evaluate.py --category bottle
```

This will compute:
- **Image-level AUROC**: Overall anomaly detection performance
- **Pixel-level AUROC**: Defect localization accuracy
- **Confusion Matrix**: TP, TN, FP, FN
- **Per-defect-type analysis**: Score distribution for each defect type

## ğŸ“Š Expected Results (Bottle Category)

Based on PatchCore paper and MVTec benchmarks:
- **Image-level AUROC**: ~98-99%
- **Pixel-level AUROC**: ~97-98%

## ğŸ”§ Advanced Usage

### Train on All Categories

```bash
python train.py --all
```

### Evaluate All Categories

```bash
python evaluate.py --all
```

### Use CPU Instead of GPU

```bash
python train.py --category bottle --device cpu
```

### Custom Configuration

Edit `config.py` to modify:
- Backbone network
- Feature extraction layers
- Coreset sampling ratio
- Number of neighbors for scoring
- Threshold computation method
- Image size

## ğŸ“ˆ Outputs

### Training
- `models/patchcore/{category}/memory_bank.npy`: Saved memory bank
- `models/patchcore/{category}/config.json`: Model configuration

### Inference
- `results/{category}/{defect_type}/{image}_result.png`: Visualization with original, heatmap, and overlay
- `results/{category}/{defect_type}/{image}_heatmap.png`: Colored heatmap

### Evaluation
- `results/{category}/evaluation/roc_curve.png`: ROC curve
- `results/{category}/evaluation/score_distribution.png`: Score distribution histogram
- Console output with detailed metrics

## ğŸ¨ Visualization Examples

Each inference result includes:
1. **Original Image**: Input image
2. **Anomaly Heatmap**: Heat map showing anomaly scores per region
3. **Overlay**: Heatmap blended with original image
4. **Ground Truth** (if available): Pixel-level defect mask

## ğŸ” How It Works

### Training Phase
1. Load defect-free images from `train/good/`
2. Extract multi-scale patch features using WideResNet50
3. Apply greedy coreset sampling to reduce memory (~10% of patches)
4. Build FAISS index for efficient nearest-neighbor search
5. Compute anomaly threshold from training data

### Inference Phase
1. Extract patch features from test image
2. For each patch, find nearest neighbor in memory bank
3. Compute distance as anomaly score
4. Generate spatial anomaly heatmap
5. Image-level score = max patch score
6. Apply threshold for binary classification

### Evaluation Phase
1. Run inference on all test images
2. Compute image-level AUROC (detection)
3. Compute pixel-level AUROC (localization)
4. Generate ROC curves and confusion matrix

## ğŸ› ï¸ Troubleshooting

### CUDA Out of Memory
- Reduce `IMAGE_SIZE` in `config.py` (e.g., from 224 to 128)
- Use `--device cpu` flag
- Reduce `CORESET_SAMPLING_RATIO`

### Slow Training
- Normal: Feature extraction is compute-intensive
- Expected time: 2-5 minutes for bottle category (GPU)
- CPU: 10-20 minutes

### Low AUROC
- Ensure you're using the correct category
- Check that training data only contains defect-free images
- Verify ground truth masks are available for evaluation

## ğŸ“ Command Reference

### Training
```bash
python train.py --category bottle          # Train single category
python train.py --all                      # Train all categories
python train.py --category bottle --device cpu  # Use CPU
```

### Inference
```bash
python inference.py --category bottle                              # All test images
python inference.py --category bottle --image path/to/image.png   # Single image
python inference.py --category bottle --no-save                   # Don't save results
```

### Evaluation
```bash
python evaluate.py --category bottle       # Evaluate single category
python evaluate.py --all                   # Evaluate all categories
python evaluate.py --category bottle --no-plots  # Skip plots
```

## ğŸŒŸ Next Steps

After validating the PatchCore engine:
1. âœ… Test on bottle category
2. âœ… Scale to all 15 categories
3. ğŸ”œ Build web application (Flask/FastAPI + React)
4. ğŸ”œ Add database for inspection history
5. ğŸ”œ Deploy as production service

## ğŸ“š References

- **PatchCore Paper**: [Towards Total Recall in Industrial Anomaly Detection](https://arxiv.org/abs/2106.08265)
- **MVTec AD Dataset**: [MVTec Anomaly Detection Dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad)

## ğŸ“„ License

This implementation is for research and educational purposes.
